{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zQr72vagFAs"
      },
      "source": [
        "# dependencies and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jDg6kqyjfwlq"
      },
      "outputs": [],
      "source": [
        "#import dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFCZvQqFhRXt"
      },
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xblKvIL0hBNf"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to not use the built in mnist dataset in torch since I want to learn how to upload files into google colab and such. It's not that complicated but nice practice. Also did not include any file upload features as uploading mnist-large files takes upwards of 30min"
      ],
      "metadata": {
        "id": "EwzvYwM0oyKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#temporary while I try finding a way to transform the csv file to the correct dimensionality\n",
        "train = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor())\n",
        "trainset = DataLoader(train, 32)\n",
        "\n",
        "#1, 28, 28 - classes: 0,1,2,3,4,5,6,7,8,9 "
      ],
      "metadata": {
        "id": "1_YqSCzQ79m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r7yNVbiVYvs"
      },
      "outputs": [],
      "source": [
        "#DONT USE\n",
        "#to be used when i have implemented a transformation of the csv file to fit the format needed\n",
        "#1 FOR USE ON COLAB WEB\n",
        "#upload files to your drive and use the correct paths\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Set path to the training and validation data\n",
        "\n",
        "path_train = \"/content/drive/MyDrive/mnist_neural_network/mnist_train.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Y5hNsSttcZGJ"
      },
      "outputs": [],
      "source": [
        "# DONT USE\n",
        "#to be used when i have implemented a transformation of the csv file to fit the format needed\n",
        "#2 FOR USE ON LOCAL MACHINE\n",
        "path_train = \"/dataset/mnist_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2IGx4cXxvsGD"
      },
      "outputs": [],
      "source": [
        "#DONT USE\n",
        "#to be used when i have implemented a transformation of the csv file to fit the format needed\n",
        "#read the files\n",
        "train = pd.read_csv(path_train)\n",
        "\n",
        "#shorten the dataset\n",
        "train = train.iloc[:15001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKAhJrDswAXM"
      },
      "outputs": [],
      "source": [
        "#DONT USE\n",
        "#to be used when i have implemented a transformation of the csv file to fit the format needed\n",
        "#convert the dataframe representations of the data to pytorch tensors and set correct device\n",
        "train = torch.from_numpy(train.values).float().to(device)\n",
        "trainset = DataLoader(train, 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "JqWnfnK3pVRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image classifier network\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Conv2d(1, 32, (3, 3)), # 1 input channel (greyscale), 32 output channel\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(32, 64, (3, 3)), # 32 input channels from previous layer\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(64, 64, (3, 3)), # 64 input channels from previous layer\n",
        "          nn.ReLU(),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(64*(28-6)*(28-6), 10)\n",
        "      ) \n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.model(x)"
      ],
      "metadata": {
        "id": "2-18O0MLpY0J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instance of neural network, loss and optimizer\n",
        "clf = ImageClassifier().to(device)\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "BRqY_xONzv2A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(epochs):\n",
        "    for batch in trainset:\n",
        "      x,y = batch\n",
        "      x,y = x.to(device), y.to(device)\n",
        "      logits = clf(x)\n",
        "      loss = loss_fn(logits, y)\n",
        "\n",
        "      opt.zero_grad(set_to_none=True)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "    print(f\"for epoch: {epoch}, the loss is {loss.item()}\")"
      ],
      "metadata": {
        "id": "YS-WMgx7qG9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "with open('model_state.pt', 'wb') as f:\n",
        "  torch.save(clf.state_dict(), f)"
      ],
      "metadata": {
        "id": "OS8ETLBjvgrk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test the model"
      ],
      "metadata": {
        "id": "P8Ha8uez9F8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#open a saved model\n",
        "with open('model_state.pt', 'rb') as f: \n",
        "    clf.load_state_dict(torch.load(f))  "
      ],
      "metadata": {
        "id": "FJNcLsmVBID-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_image = '/content/drive/MyDrive/mnist_neural_network/2.jpeg'\n",
        "img = Image.open(path_image) \n",
        "img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "print(torch.argmax(clf(img_tensor)))"
      ],
      "metadata": {
        "id": "dpLN2ymj9JwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}